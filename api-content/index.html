{"posts":[{"title":"2021/1/11 总结","content":"1.pytorch各个损失函数都有自己的前提，有时候不能混用， 举例：CrossEntropyLoss，该函数进行验证时label必须是以0开始的，即 classes=【0，1，2，3】 否则报错：Assertion `cur_target &gt;= 0 &amp;&amp; cur_target &lt; n_classes’ failed. 2.数据选择转换格式时是：dtype而不是detype，注意拼写 3.多分类时使用np.argmax（），返回numpy数组中最大值的索引，根据索引即可代表网络最后给该像素的类型值 4.代码未完全确认可以使用时，优先构建小数据集来快速验证可行性，不要出现今天这种跑了4k数据才发现eval模块出错的情况 5.softmax和sigmoid： softmax用于多分类，把多个输出映射到（0，1）区间内且这些输出的结果和为1（满足概率的特性） 和上面联动：softmax后再使用argmax来找到某个概率值最大的分类索引，得到判断结果 sigmoid：注意，是sigmoid，不是sigmiod也不是sigmod，容易写错 sigmoid就是逻辑斯蒂函数，即logistic函数，把一个实数映射到（0，1）的区间，拿来做二分类，但是注意，你拿来做多分类也行，只是多分类的值相加，不会像softmax一样各分类总值相加为1，一般来说，拿来二分类还需要给他设置个阈值，将（0，1）的值映射成0/1或者0/255 另一个方法，二分类也是多分类，那你用softmax啊！但是这时候，你的网络输出应该是2层，即最后的out_channel=2，然后argmax取值作为分类，是个好办法 5.1 知乎说法： sigmoid的优点在于输出范围有限，所以数据在传递的过程中不容易发散。当然也有相应的缺点，就是饱和的时候梯度太小。sigmoid还有一个优点是输出范围为(0, 1)，所以可以用作输出层，输出表示概率。评论中 @林孟潇指出了sigmoid的另一个优点：求导容易。 作者：王赟 Maigo 链接：https://www.zhihu.com/question/24259872/answer/82598145 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ","link":"https://mbkotori.github.io/post/2021111-zong-jie/"},{"title":"Residual Feature Aggregation Network for Image Super-Resolution","content":"翻译名:用于图像超分辨的残差特征聚合网络 abstract: 解决问题-SISR,单张图像超分辨率问题 考虑点-利用残差特征中的 残差分支-分层特征( However, existing methods neglect to fully utilize the hierarchical features on the residual branches.) 提出解决方法-提出残差特征聚合(residual feature aggregation,RFA)框架,将残差块组合在一起,并添加跳过链接[有点像densenet啊这个说法和图];提出增强空间注意力特征(enhanced spatial attention,ESA),使残差更集中于空间特征(?) 最后将RFA和ESA一同运用 introduction: SISR-直接将低分辨率LR图转成高分辨率HR图(单进单出siso),不像一般超分辨会有ms图 {读图figure1} 这里(a)实际上是一个多resblock的前向结构,每个模块包含一个resblock,由四个resblock组成 (b)中描述他们的RFA结构,先通过3个resblock前向图,他们的输出到第四个resblock,之后Res4模块输出和前三个block各自的输出concat到一块,随后1x1卷积来聚集/融合他们的特征,相对于(a)增加了1x1卷积的参数消耗 {读图figure8} 不同残差块输出的特征可以反映空间内容的不同方面 |--考虑思路:用空间注意力来提升空间信息表达能力,增强特征的空间分布 自称工作: 1.提出RFA框架 2.提出加强空间注意力ESA块 3.提出RFANet,基于RFA和ESA模块进行构建 realated work sub-pixel conv:子像素卷积,超分辨率中常用的upscale方法 https://oldpan.me/archives/upsample-convolve-efficient-sub-pixel-convolutional-layers [后续可能会出这篇文章的内容,我还没读但是看起来很有意思,他和deconv方法的不同也可以考虑进去,另一点是他能应用在SR上能不能应用在分割上,做一下考虑] {读图figure2} 基础的SR模型,卷积+多个设计好的模块+反卷积+卷积回复通道数? 基于注意力的网络模型 3.methodology 3.1 SR的简单网络结构 看作三部分: 头部:负责一个卷积层的初始特征提取,得到浅层特征F0 躯干:输入是提取到的特征F0,连接到T个basemodule的复读模式{公式2} 重建restore:将上面提取的(深层特征Ft和浅层特征F0)融合,进行放大[全局残差学习可以减轻训练难度] upsample模块是重建中的关键部分,使用子像素卷积 损失函数用L1 loss(改损失函数或许是一个很好的改进切入点) 3.2 残差特征聚合模块 残差模块包含双分支(1)残差块(2)身份块?(identity branch) 前面的残差块提取的信息很难被利用-&gt;因为它需要很长路径到达最后的卷积运算 -&gt;改进[直接将每个块的残差特征concat到一起] -&gt;concat后用1x1卷积融合他们的特征哦(这个东西可不仅仅是降维减通道) 这样的连接,不用让前面的残差信息受损或干扰-&gt;得到更具有区分性的特征表达(?) RFA可以看作一个独立模块,这也意味着我们可以把它和其他模块连接(模块复读和不同模块组合,哪个效果会好一些呢) 3.3 增强的空间注意力模块 {读图figure4} 左侧是ESAblock的形状,右侧是ESAblock中的ESA机制(mechanism) 仔细看ESA机制,对其做一个解释 ESA块放到残差块的末尾来起作用,注意力机制本质(改天可以再写一篇文章),集中体现残差特征 同时考虑到该ESA块要被连接到你后面的每个残差块,尽量不要做得太臃肿 为了完成图像SR任务,应设计一个具有较大感受野的模块(?此处没有理解.关于感受野下次可以再写一篇) 解决方法也很简单:1x1卷积降维减参数+步长卷积增大感受野 注意这里,描述的是strided conv(步长卷积)而不是dilated conv,这两者存在区别(可以详细写一下) 跨步卷积搭配池化使用#为什么/原因.可以详细描述一下 这里提到的:&quot;抛去计算量考虑,实现空间注意力块的更好方法是使用非本地模块(Non-local block)&quot;我没get到这个部分,之后要详细看一下他这里参考的两篇论文 3.4 实施细节 把RFA和ESA一同使用来构建最终的SR模块(RFANet): |-使用30个RFA模块,每个RFA包含4个ESA模块(从这里就感受到了前文为什么他们说要做一个轻便的ESA模块了) 这里的四个ESA模块也很明显:在每个resblock后,我们都给他插入一个ESA(真的有效吗....保持怀疑) 此处提到的1x1卷积的缩小率(这是个啥?),减速比? reduction ratio 3.5 讨论discussions 将文章网络和MemNet、RDN进行了讨论,描述了他们的优越性 4 实验内容 4.1 设置参数,训练等 数据集来源:DIV2K数据集 数据增强:随机旋转+翻转 batchsize=16,patch_size=48*48 数据集:Set5,Set14,B100,Urban100,Manga109 Bicubic(BI) and blur-downscale (BD) degradation models [36] are used when conducting experiments.(这部分是什么意思?没有理会到) 论文评价： 就我个人而言，这篇文章并没有太大的吸引力：RFA模块类似DenseNet结构，但是又没有很好的去解决密集连接后的参数爆炸（更有甚者他在原网络基础上又增加了ESA模块，就算通过设计使增加的参数不至于过多也是实打实地在每个模块上又添了“浓墨重彩”的一笔支出）。看似巧妙但是仔细琢磨似乎只是对网络的二度修改尝试。 另一点上，消融实验的可解释性确实不高，反而给出了一些漏洞，作者试图用实验解释自己制造的模块的作用，但是弄巧成拙，并没有取得很好的结果。 当然，作为CVPR2020录用的文章，从中我们还是能学习到一些东西的：比如文章中图表制作的合理性（我很喜欢为消融实验所做的table1和计算效率&amp;参数量的figure9，两张图既表达清晰又给人眼前一亮）；还有其中ESA模块的方法，在不能合理解释的情况下尝试他也未尝不可（作者也利用这个模块#######） ","link":"https://mbkotori.github.io/post/residual-feature-aggregation-network-for-image-super-resolution/"},{"title":"评论测试","content":"空白处,测试评论,欢迎大家留言测试! ","link":"https://mbkotori.github.io/post/ping-lun-ce-shi/"},{"title":"关于作者,和这个blog","content":"🏠 关于本站 本站属于个人纪录,分享遇到的坑,鉴于自己即将面对研究生生活,留下这么一个网站来作为自己的知识存储和记录也是非常重要的. 一开始考虑过CSDN or 博客园,考虑到审核问题放弃了,既然自己也没有什么特效需要,索性使用静态blog的形式来制作,也省去域名等麻烦. 👨‍💻 博客内容 主要会记录自己在深度学习方面出现的问题和遇到的坑,也可能分享一些自己的思考感悟(某种情况下可能会超出审核范围,大家辩证阅读即可). 个人更新时间不定,有兴趣的话题可以在留言区提出,有机会整理出来和大家一起分享. 📬 和我联系 本来是想使用Gittalk作为blog的评论系统,但是考虑到需要登陆github还是有点麻烦的,另外gittalk也存在一定的安全隐患.网站也需要一个图床来存图,索性使用了一个折衷的方案.(无利益相关) 网盘既可以作为图床,也有着一个简易的留言板可以作为评论区来供大家联系我,我会定期在上面进行回复,留言区限制1K条信息所以不重要的或者已解决的会删除. 这是 我们的评论系统,大家有问题可以在这里留言 2020/4/16 更新 因为有朋友提出Disqus还是可以在翻墙后使用的,试着配置了一下,不过发现搭载后网页加载速度明显变慢,故放弃(为了一两个评论拖慢大家阅读速度感觉不是很能接受ORZ),故放弃 或许以后修改网站结构的时候会再加上一个合适的评论系统吧~ 2020/4/17更新 使用Valine制作了一个评论系统,不过还在测试阶段,如果可以的话就继续这样使用了,大家遇到问题多提意见,我好进行相应修改! 2020/9/23更新 完全重置的网站,使用了新的模板Nature,该模板增加了搜索功能,并决定使用gitalk作为评论系统(最后还是用了最初的想法,大概是设计工作中永远的痛!) 当然,留言系统依然可以使用,方便不适用gitalk或者不想登陆的朋友! 离研究生生涯越来越近,最近可能会抽时间去写几篇堆积很久的稿子,希望继续顺利,可以研究更多感兴趣的东西! ","link":"https://mbkotori.github.io/post/about/"}]}